<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on 陈皮的博客</title>
    <link>https://y-m-m.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on 陈皮的博客</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 07 Mar 2025 09:35:44 +0800</lastBuildDate>
    <atom:link href="https://y-m-m.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>机器学习</title>
      <link>https://y-m-m.github.io/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Fri, 07 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://y-m-m.github.io/post/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid>
      <description>&lt;h1 id=&#34;1-分类与决策模型&#34;&gt;1. 分类与决策模型&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;学习任务分类&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;监督学习(supervised learning)&lt;/li&gt;&#xA;&lt;li&gt;无监督学习(unsupervised learning)&lt;/li&gt;&#xA;&lt;li&gt;半监督学习(semi-supervised learning)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一半的数据有标签&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;强化学习(reinforcement learning)&lt;/li&gt;&#xA;&lt;li&gt;弱监督学习(weak supervised learning)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;数据有标签，但标签和任务不相关&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;分类&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;分类是什么&#xA;&lt;ul&gt;&#xA;&lt;li&gt;对于给定一个对象，从一个事先定好的分类体系中挑出一个(或者多个)最适合该对象的类别&#xA;&lt;ul&gt;&#xA;&lt;li&gt;对象：可以是任何东西&lt;/li&gt;&#xA;&lt;li&gt;事先定好的分类体系：可能有结构&lt;/li&gt;&#xA;&lt;li&gt;最适合：判断标准&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;便于今后查找其最直接的映射&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;分类系统可以是层次结构&lt;/li&gt;&#xA;&lt;li&gt;分类模式&#xA;&lt;ul&gt;&#xA;&lt;li&gt;2类问题，属于或不属于&lt;/li&gt;&#xA;&lt;li&gt;多类问题，多个类别，可拆分成2类问题&lt;/li&gt;&#xA;&lt;li&gt;一个对象可以属于多类(multi-label)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;分类的基本步骤&#xA;&lt;ul&gt;&#xA;&lt;li&gt;定义分类体系&lt;/li&gt;&#xA;&lt;li&gt;将预先分类过的数据作为训练集&lt;/li&gt;&#xA;&lt;li&gt;从训练集中的处分类模型&lt;/li&gt;&#xA;&lt;li&gt;用分类模型对物体进行分类&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;分类问题的评价方式&#xA;&lt;ul&gt;&#xA;&lt;li&gt;准确率 (P, precision)  判断异常的正确率&lt;/li&gt;&#xA;&lt;li&gt;召回率 (R, recall)  从所有异常中找出异常的概率&lt;/li&gt;&#xA;&lt;li&gt;准确率与召回率很难兼得-&amp;gt;F-measure&#xA;&lt;ul&gt;&#xA;&lt;li&gt;F = 1 / (α * (1 / P) + (1 - α) * (1 / R) )&lt;/li&gt;&#xA;&lt;li&gt;(α = 0.5时) F&lt;!-- raw HTML omitted --&gt;1&lt;!-- raw HTML omitted --&gt; = 2PR / P + R&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;11-决策树基本算法&#34;&gt;1.1 决策树基本算法&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;二分类学习任务&#xA;&lt;ul&gt;&#xA;&lt;li&gt;属性&lt;/li&gt;&#xA;&lt;li&gt;属性值&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;决策树学习的目的&#xA;&lt;ul&gt;&#xA;&lt;li&gt;为了产生一颗泛化能力强的决策树，即处理未见示例能力强&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;基本算法&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;决定分类属性&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;对目前的数据表，建立一个节点N&lt;/li&gt;&#xA;&lt;li&gt;如果数据库中的数据都属于同一个类，N就是叶节点，在叶节点上标出所属的类&lt;/li&gt;&#xA;&lt;li&gt;如果数据表中没有其他属性可考虑，则N也是叶节点，按照少数服从多数的原则在叶节点上标出所属类别&lt;/li&gt;&#xA;&lt;li&gt;否则，根据属性信息增益值选出一个最佳属性作为节点N的测试属性&lt;/li&gt;&#xA;&lt;li&gt;节点属性选定后，对于该属性中的每个值再生成一个分支&lt;/li&gt;&#xA;&lt;li&gt;-&amp;gt;递归&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;关键：选择最优划分属性&#xA;&lt;ul&gt;&#xA;&lt;li&gt;希望决策树的分支节点所包含的样本尽可能属于同一类别，即节点的“纯度”越来越高&lt;/li&gt;&#xA;&lt;li&gt;衡量“纯度”的指标&#xA;&lt;ul&gt;&#xA;&lt;li&gt;信息增益&#xA;&lt;ul&gt;&#xA;&lt;li&gt;信息熵(香农用“信息熵”的概念来描述信源的不确定性)&lt;/li&gt;&#xA;&lt;li&gt;信息增益 Gain(D, a) (D是信息熵，a是属性)&lt;/li&gt;&#xA;&lt;li&gt;问题：信息增益准则对可取值数目较多的属性有所偏好&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;增益率&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Gain_ratio(D, a) = Gain(D, a) / IV(a)&lt;/li&gt;&#xA;&lt;li&gt;IV(a)属性a的“固有值“，属性a的可能的取值数目越多，IV(a)的值通常会越大&lt;/li&gt;&#xA;&lt;li&gt;增益率准则对可取值数目较少的属性有所偏好&lt;/li&gt;&#xA;&lt;li&gt;著名的C4.5决策树算法综合了信息增益准则和信息率准则的特点，先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益最高的&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;基尼指数&#xA;&lt;ul&gt;&#xA;&lt;li&gt;著名的CART决策树算法&lt;/li&gt;&#xA;&lt;li&gt;Gini(D)越小，纯度越高&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;特征选择&#xA;&lt;ul&gt;&#xA;&lt;li&gt;目标：寻找最优特征子集；剔除不相关或冗余的特征，从而达到减少特征额书，提高模型精确度，减少运行时间的目的&lt;/li&gt;&#xA;&lt;li&gt;常见方法&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Pearson相关系数&lt;/li&gt;&#xA;&lt;li&gt;卡方验证&lt;/li&gt;&#xA;&lt;li&gt;互信息和最大信息系数&lt;/li&gt;&#xA;&lt;li&gt;距离相关系数&lt;/li&gt;&#xA;&lt;li&gt;方差选择法&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;12-决策树的剪枝&#34;&gt;1.2 决策树的剪枝&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;过拟合&#xA;&lt;ul&gt;&#xA;&lt;li&gt;学习器能力过于强大，把训练样本自身的一些特点当做了所有潜在样本都会具有的一般性质，导致泛化性能下降&lt;/li&gt;&#xA;&lt;li&gt;无法彻底避免，只能做到“缓解”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;欠拟合&#xA;&lt;ul&gt;&#xA;&lt;li&gt;学习器能力低下，对训练样本的一般性质尚未学好&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;剪枝的目的：通过主动去掉一些分支来降低过拟合的风险&lt;/li&gt;&#xA;&lt;li&gt;策略&#xA;&lt;ul&gt;&#xA;&lt;li&gt;预剪枝&lt;/li&gt;&#xA;&lt;li&gt;后剪枝&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
